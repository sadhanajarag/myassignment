{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b8403c0",
   "metadata": {},
   "source": [
    "## Q1. Write a Python code to implement the KNN classifier algorithm on load_iris dataset in sklearn.datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "623bfb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "ea093aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "4e000c21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "261aacea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sepal length (cm)',\n",
       " 'sepal width (cm)',\n",
       " 'petal length (cm)',\n",
       " 'petal width (cm)']"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f4af0d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "37507e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "36287f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.data\n",
    "y = dataset.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "11a6f45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "96073d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "40e20ed3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier=KNeighborsClassifier(n_neighbors=5,algorithm='auto')\n",
    "classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "5a301fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sadha\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "#y_pred1 = log_reg.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "cd82ec1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "d2ff4c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19  0  0]\n",
      " [ 0 15  1]\n",
      " [ 0  0 15]]\n",
      "0.98\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        19\n",
      "           1       1.00      0.94      0.97        16\n",
      "           2       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98        50\n",
      "   macro avg       0.98      0.98      0.98        50\n",
      "weighted avg       0.98      0.98      0.98        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_pred,y_test))\n",
    "print(accuracy_score(y_pred,y_test))\n",
    "print(classification_report(y_pred,y_test))\n",
    "#print(roc_auc_score(y_pred,classifier.predict_proba(X),multi_class='ovr'))\n",
    " #roc_auc_score(y, clf.predict_proba(X), multi_class='ovr')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce45e95",
   "metadata": {},
   "source": [
    "## Hyperparameter tunning of KNNclassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "8040da53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
     ]
    }
   ],
   "source": [
    "grid_params = { 'n_neighbors' : [5,7,9,11,15],\n",
    "               'weights' : ['uniform','distance'],\n",
    "               'metric' : ['minkowski','euclidean','manhattan']}\n",
    "gs = GridSearchCV(KNeighborsClassifier(), grid_params, verbose = 1, cv=3, n_jobs = -1)#-1 means use all processor\n",
    "# fit the model on our train set\n",
    "g_res = gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "92a83520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9497920380273323"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the best score\n",
    "g_res.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "36b1c8c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metric': 'minkowski', 'n_neighbors': 5, 'weights': 'distance'}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the hyperparameters with the best score\n",
    "g_res.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7a8c2fdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='brute', weights='distance')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_best = KNeighborsClassifier(n_neighbors = 5, weights = 'distance',algorithm = 'brute',metric = 'minkowski')\n",
    "knn_best.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "43836aa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='brute', weights='distance')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_best.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "19554937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a prediction\n",
    "y_hat = knn_best.predict(X_train)\n",
    "y_knn = knn_best.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04c77a5",
   "metadata": {},
   "source": [
    "### model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "23923a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy:  1.0\n",
      "Test set accuracy:  0.98\n"
     ]
    }
   ],
   "source": [
    "print('Training set accuracy: ',accuracy_score(y_train, y_hat))\n",
    "print('Test set accuracy: ',accuracy_score(y_test, y_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4253456b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19  0  0]\n",
      " [ 0 15  0]\n",
      " [ 0  1 15]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, y_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5c56dc16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        19\n",
      "           1       0.94      1.00      0.97        15\n",
      "           2       1.00      0.94      0.97        16\n",
      "\n",
      "    accuracy                           0.98        50\n",
      "   macro avg       0.98      0.98      0.98        50\n",
      "weighted avg       0.98      0.98      0.98        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "27af5e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(knn_best, X, y, cv =10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "baf93681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy:  0.9666666666666668\n"
     ]
    }
   ],
   "source": [
    "print('Model accuracy: ',np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b58e86",
   "metadata": {},
   "source": [
    "As we see, we have obtained a very high model accuracy of 0.97. It is possible that the accuracy may be increased further by using more hyperparameters or with a different model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9394f196",
   "metadata": {},
   "source": [
    "## Q2. Write a Python code to implement the KNN regressor algorithm on load_boston dataset in sklearn.datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "6cdeb703",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "2a17cdcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset = load_boston()\n",
    "data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
    "raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
    "data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
    "target = raw_df.values[1::2, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "c3b946be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.00</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>396.90000</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0      1      2    3      4      5     6       7    8      9     10\n",
       "0    0.00632  18.00   2.31  0.0  0.538  6.575  65.2  4.0900  1.0  296.0  15.3\n",
       "1  396.90000   4.98  24.00  NaN    NaN    NaN   NaN     NaN  NaN    NaN   NaN\n",
       "2    0.02731   0.00   7.07  0.0  0.469  6.421  78.9  4.9671  2.0  242.0  17.8"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "9bddf7cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.3200e-03, 1.8000e+01, 2.3100e+00, ..., 1.5300e+01, 3.9690e+02,\n",
       "        4.9800e+00],\n",
       "       [2.7310e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9690e+02,\n",
       "        9.1400e+00],\n",
       "       [2.7290e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9283e+02,\n",
       "        4.0300e+00],\n",
       "       ...,\n",
       "       [6.0760e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
       "        5.6400e+00],\n",
       "       [1.0959e-01, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9345e+02,\n",
       "        6.4800e+00],\n",
       "       [4.7410e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
       "        7.8800e+00]])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "ad8d8bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sadha\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\".. _boston_dataset:\\n\\nBoston house prices dataset\\n---------------------------\\n\\n**Data Set Characteristics:**  \\n\\n    :Number of Instances: 506 \\n\\n    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\\n\\n    :Attribute Information (in order):\\n        - CRIM     per capita crime rate by town\\n        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\\n        - INDUS    proportion of non-retail business acres per town\\n        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\\n        - NOX      nitric oxides concentration (parts per 10 million)\\n        - RM       average number of rooms per dwelling\\n        - AGE      proportion of owner-occupied units built prior to 1940\\n        - DIS      weighted distances to five Boston employment centres\\n        - RAD      index of accessibility to radial highways\\n        - TAX      full-value property-tax rate per $10,000\\n        - PTRATIO  pupil-teacher ratio by town\\n        - B        1000(Bk - 0.63)^2 where Bk is the proportion of black people by town\\n        - LSTAT    % lower status of the population\\n        - MEDV     Median value of owner-occupied homes in $1000's\\n\\n    :Missing Attribute Values: None\\n\\n    :Creator: Harrison, D. and Rubinfeld, D.L.\\n\\nThis is a copy of UCI ML housing dataset.\\nhttps://archive.ics.uci.edu/ml/machine-learning-databases/housing/\\n\\n\\nThis dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\\n\\nThe Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\\nprices and the demand for clean air', J. Environ. Economics & Management,\\nvol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\\n...', Wiley, 1980.   N.B. Various transformations are used in the table on\\npages 244-261 of the latter.\\n\\nThe Boston house-price data has been used in many machine learning papers that address regression\\nproblems.   \\n     \\n.. topic:: References\\n\\n   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\\n   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\\n\""
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset1 = load_boston()\n",
    "dataset1.DESCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "6b9d694f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data\n",
    "y = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "26c492a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "46260e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import r2_score,mean_absolute_error,mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "c7c4b3d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsRegressor()"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_reg=KNeighborsRegressor()\n",
    "classifier_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "4028689f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32.17596886227545\n",
      "5.6723865226441905\n",
      "0.5748334691810936\n",
      "4.148862275449102\n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier_reg.predict(X_test)\n",
    "print(mean_squared_error(y_test,y_pred))\n",
    "print(sqrt(mean_squared_error(y_test,y_pred)))\n",
    "print(r2_score(y_test,y_pred))\n",
    "print(mean_absolute_error(y_test,y_pred))\n",
    "#y_pred1 = log_reg.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "0dbc2560",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error \n",
    "from math import sqrt\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "e6ab6302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE value for k=  1 is: 5.6723865226441905\n",
      "RMSE value for k=  2 is: 5.6723865226441905\n",
      "RMSE value for k=  3 is: 5.6723865226441905\n",
      "RMSE value for k=  4 is: 5.6723865226441905\n",
      "RMSE value for k=  5 is: 5.6723865226441905\n",
      "RMSE value for k=  6 is: 5.6723865226441905\n",
      "RMSE value for k=  7 is: 5.6723865226441905\n",
      "RMSE value for k=  8 is: 5.6723865226441905\n",
      "RMSE value for k=  9 is: 5.6723865226441905\n",
      "RMSE value for k=  10 is: 5.6723865226441905\n"
     ]
    }
   ],
   "source": [
    "rmse_val = [] #to store rmse values for different k\n",
    "for K in range(10):\n",
    "    K = K+1\n",
    "    model =KNeighborsRegressor(n_neighbors = K)\n",
    "    model.fit(X_train, y_train)  #fit the model\n",
    "    pred=model.predict(X_test) #make prediction on test set\n",
    "    error = sqrt(mean_squared_error(y_test,y_pred)) #calculate rmse\n",
    "    rmse_val.append(error) #store rmse values\n",
    "    print('RMSE value for k= ' , K , 'is:', error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "7e411ca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plotting the rmse values against k values\n",
    "curve = pd.DataFrame(rmse_val) #elbow curve \n",
    "curve.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570a0c32",
   "metadata": {},
   "source": [
    "## Hyperparameter Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "f71786f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
     ]
    }
   ],
   "source": [
    "grid_params = { 'n_neighbors' : [5,7,9,11,15],\n",
    "               'weights' : ['uniform','distance'],\n",
    "               'metric' : ['minkowski','euclidean','manhattan']}\n",
    "gs_reg = GridSearchCV(KNeighborsRegressor(), grid_params, verbose = 1, cv=3, n_jobs = -1)#-1 means use all processor\n",
    "# fit the model on our train set\n",
    "g_reg = gs_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "fd62a1b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.543085782079651"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_reg.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "290fe5ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metric': 'manhattan', 'n_neighbors': 5, 'weights': 'distance'}"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_reg.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f1486d",
   "metadata": {},
   "source": [
    "#### Fit with best param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "e6a54b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_reg_best = KNeighborsRegressor(n_neighbors = 5,metric='manhattan',weights='distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "438f31b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_reg_best = knn_reg_best.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "b43cf375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32.17596886227545\n",
      "5.6723865226441905\n",
      "0.5748334691810936\n",
      "4.148862275449102\n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier_reg.predict(X_test)\n",
    "print(mean_squared_error(y_test,y_pred))\n",
    "print(sqrt(mean_squared_error(y_test,y_pred)))\n",
    "print(r2_score(y_test,y_pred))\n",
    "print(mean_absolute_error(y_test,y_pred))\n",
    "#y_pred1 = log_reg.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b6d4d1",
   "metadata": {},
   "source": [
    "## Q3. Write a Python code snippet to find the optimal value of K for the KNN classifier algorithm using cross-validation on load_iris dataset in sklearn.datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "807258a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "59018996",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "79eaa2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.data\n",
    "y = dataset.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "f2083859",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "22131ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_best1 = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "cf64da90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_best1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "af7f1d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "854a5b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "3ce69131",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sadha\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\Sadha\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\Sadha\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\Sadha\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\Sadha\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\Sadha\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\Sadha\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\Sadha\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\Sadha\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\Sadha\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "scores1 = cross_val_score(knn_best1, X, y, cv =10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "1fb3d2e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9666666666666668\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(scores1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5eb8f4",
   "metadata": {},
   "source": [
    "## Q4. Implement the KNN regressor algorithm with feature scaling on load_boston dataset in sklearn.datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "0462b348",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "a46aacfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset = load_boston()\n",
    "data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
    "raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
    "data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
    "target = raw_df.values[1::2, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "d4667771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.3200e-03, 1.8000e+01, 2.3100e+00, ..., 1.5300e+01, 3.9690e+02,\n",
       "        4.9800e+00],\n",
       "       [2.7310e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9690e+02,\n",
       "        9.1400e+00],\n",
       "       [2.7290e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9283e+02,\n",
       "        4.0300e+00],\n",
       "       ...,\n",
       "       [6.0760e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
       "        5.6400e+00],\n",
       "       [1.0959e-01, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9345e+02,\n",
       "        6.4800e+00],\n",
       "       [4.7410e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
       "        7.8800e+00]])"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "ab7d5b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data\n",
    "y = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "24002528",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "e22c13bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import r2_score,mean_absolute_error,mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "faacf8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train =scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "01ff3b66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsRegressor()"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_reg_sc=KNeighborsRegressor()\n",
    "classifier_reg_sc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "d9700dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.066237125748508\n",
      "4.3664902525653835\n",
      "0.7480627256564338\n",
      "2.714491017964072\n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier_reg_sc.predict(X_test)\n",
    "print(mean_squared_error(y_test,y_pred))\n",
    "print(sqrt(mean_squared_error(y_test,y_pred)))\n",
    "print(r2_score(y_test,y_pred))\n",
    "print(mean_absolute_error(y_test,y_pred))\n",
    "#y_pred1 = log_reg.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a284ef1e",
   "metadata": {},
   "source": [
    "## Q5. Write a Python code snippet to implement the KNN classifier algorithm with weighted voting on load_iris dataset in sklearn.datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "8ab26612",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "dataset = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "2e7656da",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.data\n",
    "y = dataset.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "c9002a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "c3189919",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(weights= 'uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "796a9209",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "575c8f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sadha\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "y_pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "93a7ff29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[16  0  0]\n",
      " [ 0 14  0]\n",
      " [ 0  0 15]]\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       1.00      1.00      1.00        14\n",
      "           2       1.00      1.00      1.00        15\n",
      "\n",
      "    accuracy                           1.00        45\n",
      "   macro avg       1.00      1.00      1.00        45\n",
      "weighted avg       1.00      1.00      1.00        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_pred,y_test))\n",
    "print(accuracy_score(y_pred,y_test))\n",
    "print(classification_report(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "64d00379",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_1 = KNeighborsClassifier(weights= 'distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "48662c81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(weights='distance')"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "61c1301e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sadha\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "y_pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "fb5e825c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[16  0  0]\n",
      " [ 0 14  0]\n",
      " [ 0  0 15]]\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       1.00      1.00      1.00        14\n",
      "           2       1.00      1.00      1.00        15\n",
      "\n",
      "    accuracy                           1.00        45\n",
      "   macro avg       1.00      1.00      1.00        45\n",
      "weighted avg       1.00      1.00      1.00        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_pred,y_test))\n",
    "print(accuracy_score(y_pred,y_test))\n",
    "print(classification_report(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ceb90ec",
   "metadata": {},
   "source": [
    "## Q6. Implement a function to standardise the features before applying KNN classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ad10c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def knn_with_standardization(X_train, y_train, X_test, n_neighbors):\n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    # Fit KNN classifier\n",
    "    knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    knn.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = knn.predict(X_test)\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff8f8c9",
   "metadata": {},
   "source": [
    "## Q7. Write a Python function to calculate the euclidean distance between two points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "26777535",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def euclidean_distance(p1, p2):\n",
    "    distance = 0\n",
    "    for i in range(len(p1)):\n",
    "        distance += (p1[i] - p2[i])**2\n",
    "    return math.sqrt(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "63eff17a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.196152422706632"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1 = (1, 2, 3)\n",
    "p2 = (4, 5, 6)\n",
    "euclidean_distance(p1, p2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff94504f",
   "metadata": {},
   "source": [
    "## Q8. Write a Python function to calculate the manhattan distance between two points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "fd0ac1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def manhattan_distance(p1, p2):\n",
    "    distance = 0\n",
    "    for i in range(len(p1)):\n",
    "        distance += abs(p1[i] - p2[i])\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "5d7f4e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "p1 = (1, 2, 3)\n",
    "p2 = (4, 5, 6)\n",
    "distance = manhattan_distance(p1, p2)\n",
    "print(distance)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
