{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7f9f0fd",
   "metadata": {},
   "source": [
    "## Q1. Explain the assumptions required to use ANOVA and provide examples of violations that could impact the validity of the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d012a21a",
   "metadata": {},
   "source": [
    "An ANOVA (analysis of variance) is used to determine whether or not there is a statistically significant difference between the means of three or more independent groups. \n",
    "\n",
    "For example, suppose we want to know whether or not studying technique has an impact on exam scores for a class of students. We randomly split the class into three groups. Each group uses a different studying technique for one month to prepare for an exam. At the end of the month, all of the students take the same exam.\n",
    "\n",
    "To find out if studying technique impacts exam scores, we can conduct a one-way ANOVA, which will tell us if if there is a statistically significant difference between the mean scores of the three group\n",
    "\n",
    "\n",
    "To use the ANOVA test we made the following assumptions:\n",
    "\n",
    "1) Normality : Each group sample is drawn from a normally distributed population\n",
    "2) Homogeneity : All populations have a common variance within each group.\n",
    "3) Independant of Error : The Error should be independent for each value .All samples are drawn independently of each other\n",
    "4) Within each sample, the observations are sampled randomly and independently of each other\n",
    "5) Factor effects are additive\n",
    "\n",
    "Examples of violations that could impact the validity of the results:\n",
    "\n",
    "1) Nonnormality : \n",
    "            The boxplot, histogram, and normal probability plot (normal Q-Q plot), along with the normality test, can provide    information on the normality the population distribution.\n",
    "             However, if there are only a small number of data points, nonnormality can be hard to detect.\n",
    "    The one-way ANOVA's F test will not be much affected even if the population distributions are skewed, but the F test can be sensitive to population skewness if the sample sizes are seriously unbalanced. \n",
    "   If the sample sizes are not unbalanced, the F test will not be seriously affected by light-tailedness or heavy-tailedness, unless the sample sizes are small (less than 5), or the departure from normality is extreme and if outlier is not present.\n",
    "\n",
    "2) Unequal population variances:\n",
    "    The inequality of the population variances can be assessed by examination of the relative size of the sample variances, either informally (including graphically), or by a robust variance test such as Levene's test.\n",
    "    The F test is fairly robust against inequality of variances if the sample sizes are equal, although the chance increases of incorrectly reporting a significant difference in the means when none exists. This chance of incorrectly rejecting the null hypothesis is greater when the population variances are very different from each other, particularly if there is one sample variance very much larger than the others. \n",
    "    The effect of inequality of the variances is most severe when the sample sizes are unequal. If the larger samples are associated with the populations with the larger variances, then the F statistic will tend to be smaller than it should be, reducing the chance that the test will correctly identify a significant difference between the means (i.e., making the test conservative). On the other hand, if the smaller samples are associated with the ulations with the larger variances, then the F statistic will tend to be greater than it should be, increasing the risk of incorrectly reporting a significant difference in the means when none exists. This chance of incorrectly rejecting the null hypothesis in the case of unbalanced sample sizes can be substantial even when the population variances are not very different from each other.\n",
    "    solution :\n",
    "     If both nonnormality and unequal variances are present, employing a transformation may be preferable. A nonparametric test like the Kruskal-Wallis test still assumes that the population variances are comparable.\n",
    "     \n",
    "3) Outliers: \n",
    "    Values may not be identically distributed because of the presence of outliers. Outliers are anomalous values in the data. Outliers tend to increase the estimate of sample variance, thus decreasing the calculated F statistic for the ANOVA and lowering the chance of rejecting the null hypothesis. \n",
    " \n",
    "4) Lack of independence:\n",
    "    If samples are dependent of each other then it would be defficult as effect of one sample will be on another and it effect correct measuremnet of test statastics.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a36265",
   "metadata": {},
   "source": [
    "## Q2. What are the three types of ANOVA, and in what situations would each be used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db59745",
   "metadata": {},
   "source": [
    "One Way ANOVA:\n",
    "\n",
    "--> A one way ANOVA is used to compare two means from two independent (unrelated) groups using the F-distribution.\n",
    "\n",
    "--> only one independent categorical factor \n",
    "\n",
    "Ex.Sale Pramotion and this factor can have multiple level like high ,medium and low.\n",
    "\n",
    "Null hypothesis:  the two means are equal. \n",
    "\n",
    "Alternate Hypothesis : significant result means that the two means are unequal.\n",
    "\n",
    "\n",
    "Two Way ANOVA:\n",
    "\n",
    "Two Way ANOVA, there are two independents. Use a two way ANOVA when you have one measurement variable (i.e. a quantitative variable) and two nominal variables. In other words, if your experiment has a quantitative outcome and you have two categorical explanatory variables, a two way ANOVA is appropriate.\n",
    "\n",
    "-->2 independent categorical factors    \n",
    "-->Each factor can have multiple levels\n",
    "\n",
    "For example, you might want to find out if there is an interaction between income and gender for anxiety level at job interviews. The anxiety level is the outcome, or the variable that can be measured. Gender and Income are the two categorical variables.\n",
    "\n",
    "There are two types of Two way anova:\n",
    "\n",
    "Lets take example :\n",
    "\n",
    "For example, a botanist might want to know if sunlight exposure (None, Low, Medium, High) and watering frequency (Daily, Weekly) have a statistically significant effect on plant growth.\n",
    "\n",
    "Two-way ANOVA is performed in two ways:\n",
    "\n",
    "Two-way ANOVA with replication: \n",
    "\n",
    "            It is performed when there are two groups and the members of these groups are doing more than one thing.  \n",
    "For each combination of levels for the predictor variables, there are multiple observations.\n",
    "\n",
    "Using this approach, the botanist would measure the growth of multiple plants for each combination of levels for sunlight and watering frequency.\n",
    "For example, she might measure the growth of five different plants that had no sunlight exposure and daily watering.\n",
    "Then she would measure the growth of another five plants that had no sunlight exposure and weekly watering.\n",
    "\n",
    "Two-way ANOVA without replication:\n",
    "\n",
    "            This is used when you have only one group but you are double-testing that group. For example, a patient is being observed before and after medication. \n",
    "For each combination of levels for the predictor variables, there is only one observation.\n",
    "\n",
    "example : Using this approach, the botanist would only measure the growth of one plant for each combination of levels for sunlight and watering frequency.\n",
    "For example, she would measure the growth of one plant that had no sunlight exposure and daily watering.\n",
    "\n",
    "Assumptions for Two Way ANOVA\n",
    "\n",
    "- The population must be close to a normal distribution.\n",
    "- Samples must be independent.\n",
    "- Population variances must be equal (i.e. homoscedastic).\n",
    "- Groups must have equal sample sizes.\n",
    "\n",
    "N-Way ANOVA (MANOVA):\n",
    "\n",
    "MANOVA is just an ANOVA with several dependent variables. It’s similar to many other tests and experiments in that it’s purpose is to find out if the response variable (i.e. your dependent variable) is changed by manipulating the independent variable. \n",
    "\n",
    "Example :\n",
    "\n",
    "Suppose you wanted to find out if a difference in textbooks affected students’ scores in math and science. Improvements in math and science means that there are two dependent variables, so a MANOVA is appropriate.\n",
    "\n",
    "it answers the following questions:\n",
    "\n",
    "Does the change in the independent variable significantly affect the dependent variable? \n",
    "\n",
    "What are interactions among the dependent variables?\n",
    "\n",
    "What are interactions between independent variables?\n",
    "\n",
    " \n",
    "An ANOVA will give you a single (univariate) f-value while a MANOVA will give you a multivariate F value.\n",
    "MANOVA tests the multiple dependent variables by creating new, artificial, dependent variables that maximize group differences. These new dependent variables are linear combinations of the measured dependent variables.\n",
    "\n",
    "\n",
    "Advantages and Disadvantages of MANOVA vs. ANOVA\n",
    "\n",
    "Advantages:\n",
    "\n",
    "1) MANOVA enables you to test multiple dependent variables.\n",
    "2) MANOVA can protect against Type I errors.\n",
    "\n",
    "Disadvantages:\n",
    "\n",
    "1) MANOVA is many times more complicated than ANOVA, making it a challenge to see which independent variables are affecting dependent variables.\n",
    "2) One degree of freedom is lost with the addition of each new variable.\n",
    "3) The dependent variables should be uncorrelated as much as possible. If they are correlated, the loss in degrees of freedom means that there isn’t much advantages in including more than one dependent variable on the test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349eb258",
   "metadata": {},
   "source": [
    "## Q3. What is the partitioning of variance in ANOVA, and why is it important to understand this concept?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540fcc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "The Formula for ANOVA\n",
    "\n",
    "F= MS(between)\n",
    "/MS(within)\n",
    "\n",
    "The F statistic — is calculated by dividing the between group variance by the within group variance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ff9700",
   "metadata": {},
   "source": [
    "Partitioning of Varience :\n",
    "\n",
    "Between Group Variation:\n",
    "    \n",
    "    The total variation between each group mean and the overall mean.\n",
    "    Here between group varience means that the value of group mean and the value of your sample is how far or the varience between them.\n",
    "    \n",
    "Within the group Varience:\n",
    "    \n",
    "    The total variation in the individual values in each group and their group mean.\n",
    "    Here the value of sample and the mean of that sample are they same or nor if not then how far that value is.\n",
    "    \n",
    "       Within-group variation (sometimes called error group or error variance) is a term used in ANOVA tests. It refers to variations caused by differences within individual groups (or levels). In other words, not all the values within each group (e.g. means) are the same.\n",
    "  \n",
    "\n",
    "All  anova statstic based on these concept.\n",
    "\n",
    "The varience of methods also allows you to compare more than two groups simultaneously to test whether the relationship exists between them or not.\n",
    "\n",
    "What is the purpose of the Analysis of Variance?\n",
    "\n",
    "An ANOVA examines the relationship between a categorical and a numeric variable by judging the differences between two or more means. This analysis gives a p-value to decide whether the relationship is vital or not.\n",
    "\n",
    "When to use ANOVA (Analysis of Variance)?\n",
    "\n",
    "You might use Analysis of Variance (ANOVA) as a marketer when you want to test a specific theory. You would use ANOVA to understand how your different groups react, with a null hypothesis for the test that means the various groups are equal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39882bae",
   "metadata": {},
   "source": [
    "## Q4. How would you calculate the total sum of squares (SST), explained sum of squares (SSE), and residual sum of squares (SSR) in a one-way ANOVA using Python?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53206ac",
   "metadata": {},
   "source": [
    "1. Sum of Squares Regression (SSR):\n",
    "                This is the sum of the squared differences between each group mean and the grand mean.\n",
    "               The sum of squared differences between predicted data points (ŷi) and the mean of the response variable(ybar).\n",
    "\n",
    "                SSR = Σ(ŷi – ybar)2\n",
    "\n",
    "\n",
    "2. Sum of Squares Error (SSE):\n",
    "                This is the sum of the squared differences between each individual observation and the group mean of that                       observation.\n",
    "                The sum of squared differences between predicted data points (ŷi) and observed data points (yi).\n",
    "\n",
    "                SSE = Σ(ŷi – yi)2\n",
    "\n",
    "3. Sum of Squares Total (SST):\n",
    "               This is the sum of the squared differences between each individual observation and the grand mean.\n",
    " 1. Sum of Squares Total (SST) – The sum of squared differences between individual data points (yi) and the mean of the response variable (ybar).\n",
    " \n",
    "                SST = Σ(yi – ybar)2\n",
    "                \n",
    " The following relationship exists between these three measures:\n",
    "\n",
    "                    SST = SSR + SSE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e74743d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "group1 =np.array([85,86,88,75,78,94,98,79,71,80])\n",
    "group2 =np.array([91,92,93,85,87,84,82,88,95,96])\n",
    "group3 =np.array([79,78,88,94,92,85,83,85,82,81])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75e27502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[85 86 88 75 78 94 98 79 71 80] [91 92 93 85 87 84 82 88 95 96] [79 78 88 94 92 85 83 85 82 81]\n"
     ]
    }
   ],
   "source": [
    "print(group1,group2,group3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "62646c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSR :  192.19999999999948 SSE :  1100.6000000000001 SST :  1292.7999999999997\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'SSR : 192.19999999999948SSE : 1100.6000000000001SST : 1292.7999999999997'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculate SSR :nΣ(Xj – X..)2\n",
    "#Calculate SSE:Σ(Xij – Xj)2 \n",
    "#Step 4: Calculate SST\n",
    "\n",
    "def ssr(group1,group2,group3,n):\n",
    "    group1_mean=sum(group1)/n\n",
    "    group2_mean=sum(group2)/n\n",
    "    group3_mean=sum(group3)/n\n",
    "    all_grp_mean =(group1_mean+group2_mean+group3_mean)/3\n",
    "    #print(group1_mean,group2_mean,group2_mean,all_grp_mean)\n",
    "    SSR = n*(group1_mean-all_grp_mean)**2 + n*(group2_mean-all_grp_mean)**2 + n*(group3_mean-all_grp_mean)**2\n",
    "    sse_group1= sum((group1_mean-group1)**2)\n",
    "    sse_group2= sum((group2_mean-group2)**2)\n",
    "    sse_group3= sum((group3_mean-group3)**2)\n",
    "    SSE=sse_group1+sse_group2+sse_group3\n",
    "    SST = SSR+SSE\n",
    "    print(\"SSR : \",SSR,\"SSE : \",SSE,\"SST : \",SST)\n",
    "    #return SSR,SSE,SST\n",
    "    return \"SSR : \"+str(SSR)+\"SSE : \"+str(SSE)+\"SST : \"+str(SST)\n",
    "\n",
    "ssr(group1,group2,group3,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee89104",
   "metadata": {},
   "source": [
    "## Q5. In a two-way ANOVA, how would you calculate the main effects and interaction effects using Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "90f6d37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#create data\n",
    "df = pd.DataFrame({'Gender': np.repeat(['Male', 'Female'], 12),\n",
    "                   'Noise': np.tile(np.repeat(['Low', 'Med', 'High'], 4), 2),\n",
    "                   'Data': [10,12,11,9,7,9,8,12,4,5,6,5,12,13,10,13,13,15,12,12,6,6,4,4]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e3e918",
   "metadata": {},
   "outputs": [],
   "source": [
    "Main Effect : (The Independent factors have effect on dependent factor)\n",
    "                Does Noise have effect on mark of student\n",
    "                Does Gender have effect on mark of student\n",
    "Interraction Effect : (Interaction of all factors effect on dependent factor)\n",
    "                    Does gender effected that how student react to the noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fbaef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Hypothesis :\n",
    "    H0 : There is no effect of one variable to other\n",
    "    H1 : There is effect of one variable to other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877c1b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "N=24 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "97588a1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Noise</th>\n",
       "      <th>Data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Male</td>\n",
       "      <td>Low</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Male</td>\n",
       "      <td>Low</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>Low</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Male</td>\n",
       "      <td>Low</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Male</td>\n",
       "      <td>Med</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Male</td>\n",
       "      <td>Med</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Male</td>\n",
       "      <td>Med</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Male</td>\n",
       "      <td>Med</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Male</td>\n",
       "      <td>High</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Male</td>\n",
       "      <td>High</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Male</td>\n",
       "      <td>High</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Male</td>\n",
       "      <td>High</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Female</td>\n",
       "      <td>Low</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Female</td>\n",
       "      <td>Low</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Female</td>\n",
       "      <td>Low</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Female</td>\n",
       "      <td>Low</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Female</td>\n",
       "      <td>Med</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Female</td>\n",
       "      <td>Med</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Female</td>\n",
       "      <td>Med</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Female</td>\n",
       "      <td>Med</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Female</td>\n",
       "      <td>High</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Female</td>\n",
       "      <td>High</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Female</td>\n",
       "      <td>High</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Female</td>\n",
       "      <td>High</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Gender Noise  Data\n",
       "0     Male   Low    10\n",
       "1     Male   Low    12\n",
       "2     Male   Low    11\n",
       "3     Male   Low     9\n",
       "4     Male   Med     7\n",
       "5     Male   Med     9\n",
       "6     Male   Med     8\n",
       "7     Male   Med    12\n",
       "8     Male  High     4\n",
       "9     Male  High     5\n",
       "10    Male  High     6\n",
       "11    Male  High     5\n",
       "12  Female   Low    12\n",
       "13  Female   Low    13\n",
       "14  Female   Low    10\n",
       "15  Female   Low    13\n",
       "16  Female   Med    13\n",
       "17  Female   Med    15\n",
       "18  Female   Med    12\n",
       "19  Female   Med    12\n",
       "20  Female  High     6\n",
       "21  Female  High     6\n",
       "22  Female  High     4\n",
       "23  Female  High     4"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b927fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sorce of variation              Sum of square             Df            Mean Sqaure=SS/df     F value               by f-table  at 0.05\n",
    "\n",
    "Between rows(gender)               SSr=20.17           2-1=1(r-1)       MSSr=20.17/1 = 20.17    Fr=MSSr/MSSe=9.79    f(1,18)=3.55\n",
    "\n",
    "                                                    \n",
    "\n",
    "Between column(noise)                SSc=200.33          3-1=2(c-1)        MSSc=200.33/2 = 100.16   Fc=MSSc/MSSe=48.62 f(2,18)=4.41\n",
    " \n",
    "\n",
    "Interaction R and C              SSI =  16.33        2*1=2=(c-1)*        MSSg = 16.33/2 =8.167     Fg=MSSg/2.06= 3.97  f(2,18)=3.55\n",
    "                                                    (r-1)\n",
    "    \n",
    "Residual                       c*r*(n-1)=18\n",
    "                               n=no of student in grp   37               MSSe =SSI/18   =2.06       \n",
    "                                n=4\n",
    "\n",
    "Total                       273.8333                     N=24-1=23\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "03ab212b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value by calculation: Row,column and interaction respectively  9.810810810810738 48.72972972972972 3.97297297297301\n",
      "Value by Table: Row,column and interaction respectively  3.554557145661787 4.413873419170566 3.554557145661787\n",
      "Reject H0\n",
      "Reject H0\n",
      "Reject H0\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "def two_way_anova(df):\n",
    "    # Get data in rows\n",
    "    Df=len(df['Data'])\n",
    "    Dfr=df.nunique()['Gender']\n",
    "    Dfc=df.nunique()['Noise']\n",
    "    df1=df.loc[(df.Gender =='Female') & (df.Noise == 'High')].count()\n",
    "    n=df1.iloc[1]\n",
    "    #print(Dfr,Dfc,n)\n",
    "    grp1 = df.loc[(df.Gender =='Male') & (df.Noise == 'Low'), 'Data'].sum() \n",
    "    grp2 = df.loc[(df.Gender =='Male') & (df.Noise == 'Med'), 'Data'].sum() \n",
    "    grp3 = df.loc[(df.Gender =='Male') & (df.Noise == 'High'), 'Data'].sum() \n",
    "    #sum of row which is value 'Male'\n",
    "    R1 = df.loc[(df.Gender =='Male'),'Data'].sum()\n",
    "    #print(R1)\n",
    "    # Get data in rows\n",
    "    grp4 = df.loc[(df.Gender =='Female') & (df.Noise == 'Low'), 'Data'].sum() \n",
    "    grp5 = df.loc[(df.Gender =='Female') & (df.Noise == 'Med'), 'Data'].sum() \n",
    "    grp6 =df.loc[(df.Gender =='Female') & (df.Noise == 'High'), 'Data'].sum() \n",
    "    #print(grp4,grp5,grp6)\n",
    "    #sum of row which is value 'Feale'\n",
    "    R2 = df.loc[(df.Gender =='Female'),'Data'].sum()\n",
    "    #print(R2)\n",
    "    #get column wise data\n",
    "    C1 = df.loc[(df.Noise=='Low'),'Data'].sum()\n",
    "    C2 = df.loc[(df.Noise=='Med'),'Data'].sum()\n",
    "    C3 = df.loc[(df.Noise=='High'),'Data'].sum()\n",
    "    #print(C1,C2,C3)\n",
    "    # Step1 : Calculate Correction Term:sum of square of observation/no of observation\n",
    "    Cr= df['Data'].sum()**2/len(df['Data'])\n",
    "    #print(Cr)\n",
    "    #Calculate sum of sqaure of Total\n",
    "    SST= sum (df['Data']*df['Data'])-Cr\n",
    "    #print(SST)\n",
    "    #For Variation of Noise get sum of total of column.i.e sum of sqaure of column\n",
    "    # 8 as 8 value in column\n",
    "    #Sum of sqaure of column = sum of sqaure of column/a-cr\n",
    "    SSc=(C1**2+C2**2+C3**2)/8 - Cr\n",
    "    #print(SSc)\n",
    "    #For Variation of Gender get sum of total of rows.i.e sum of sqaure of rows\n",
    "    # 12 as 12 value each unique row i.e male 12 and female 12\n",
    "    SSr=(R1**2+R2**2)/12 - Cr\n",
    "    #print(SSr)\n",
    "    #Sum of sqaure within the group\n",
    "    grp1_mean = grp1/4\n",
    "    grp2_mean = grp2/4\n",
    "    grp3_mean = grp3/4\n",
    "    grp4_mean = grp4/4\n",
    "    grp5_mean = grp5/4\n",
    "    grp6_mean = grp6/4\n",
    "    #print(grp1_mean,grp2_mean,grp3_mean,grp4_mean,grp5_mean,grp6_mean)\n",
    "    #print(grp1_mean)\n",
    "    #There are 6 different group form as 2 row and 3 column =6\n",
    "    #SSg=(grp1**2+grp2**2+grp3**2+grp4**2+grp5**2+grp6**2)/6-Cr-SSc-SSr\n",
    "    #print(SSg)\n",
    "    R1=sum((df.loc[(df.Gender =='Male') & (df.Noise == 'Low'),'Data']-grp1_mean)**2)\n",
    "    R2=sum((df.loc[(df.Gender =='Male') & (df.Noise == 'Med'),'Data']-grp2_mean)**2)\n",
    "    R3=sum((df.loc[(df.Gender =='Male') & (df.Noise == 'High'),'Data']-grp3_mean)**2)\n",
    "    R4=sum((df.loc[(df.Gender =='Female') & (df.Noise == 'Low'),'Data']-grp4_mean)**2)\n",
    "    R5=sum((df.loc[(df.Gender =='Female') & (df.Noise == 'Med'),'Data']-grp5_mean)**2)\n",
    "    R6=sum((df.loc[(df.Gender =='Female') & (df.Noise == 'High'),'Data']-grp6_mean)**2)\n",
    "    #result = df.loc['A'==12.0, 'D']\n",
    "    sum_of_sqaure_withon_grp=R1+R2+R3+R4+R5+R6\n",
    "    #print(\"sum_of_sqaure_withon_grp :\",sum_of_sqaure_withon_grp)\n",
    "    #SS Interaction = SS Total – SS Factor 1(row) – SS Factor 2(column) – SS Within\n",
    "    SSI=SST-SSr-SSc-sum_of_sqaure_withon_grp\n",
    "    #print(\"SS Interaction:\",SSI)\n",
    "    MSSr=SSr/(Dfr-1)\n",
    "    #print(MSSr)\n",
    "    MSSc=SSc/(Dfc-1)\n",
    "    #print(MSSc)\n",
    "    MSSg=SSI/((Dfr-1)*(Dfc-1))\n",
    "    #print(MSSg)\n",
    "    MSSe=sum_of_sqaure_withon_grp/(Dfr*Dfc*(n-1))\n",
    "    #print(\"M\",MSSe)\n",
    "    Fr=MSSr/MSSe\n",
    "    Fc=MSSc/MSSe\n",
    "    Fe=MSSg/MSSe\n",
    "    #Value by F table\n",
    "    Ftr = scipy.stats.f.ppf(q=1-.05, dfn=2, dfd=18)\n",
    "    Ftc = scipy.stats.f.ppf(q=1-.05, dfn=1, dfd=18)\n",
    "    Fte = scipy.stats.f.ppf(q=1-.05, dfn=2, dfd=18)\n",
    "    print(\"Value by calculation: Row,column and interaction respectively \",Fr,Fc,Fe)\n",
    "    print(\"Value by Table: Row,column and interaction respectively \",Ftr,Ftc,Fte)\n",
    "    if Fr>Ftr:\n",
    "        print(\"Reject H0\")\n",
    "    else:\n",
    "        print(\"Failed to Reject H0\")\n",
    "        \n",
    "    if Fc>Ftc:\n",
    "        print(\"Reject H0\")\n",
    "    else:\n",
    "        print(\"Failed to Reject H0\")\n",
    "    if Fe>Fte:\n",
    "        print(\"Reject H0\")\n",
    "    else:\n",
    "        print(\"Failed to Reject H0\")\n",
    "    \n",
    "two_way_anova(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "9e752280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.756939234808702"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#For noise(column)=F(cal)>F(table)  : reject H0\n",
    "#For gender(row)=F(cal)>F(table):reject H0\n",
    "#For interaction=F(cal)>F(table) : reject H0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad97c912",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inference :There is effect of one variable to other"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9772dd2d",
   "metadata": {},
   "source": [
    "## Q6. Suppose you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02. What can you conclude about the differences between the groups, and how would you interpret these results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2fc4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "The F test statistic is 5.23 and the corresponding p-value is 0.02. \n",
    "Since the p-value is  less than .05,we  reject the null hypothesis.\n",
    "This means we do  have sufficient evidence to say that there is diffrence between the groups\n",
    "\n",
    "H0 (null hypothesis): μ1 = μ2 (all the population means are equal)\n",
    "H1 (null hypothesis): at least one population mean is different from the rest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7443e6",
   "metadata": {},
   "source": [
    "## Q7. In a repeated measures ANOVA, how would you handle missing data, and what are the potential consequences of using different methods to handle missing data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b153d8",
   "metadata": {},
   "source": [
    "1) The simplest approach--listwise deletion:\n",
    "\n",
    "   By far the most common approach to missing data is to simply omit those cases with missing data and to run our analyses on what remains\n",
    "   i.e remove that record from the sample and do statastic on remaining data.\n",
    "\n",
    "   Consequence:\n",
    "\n",
    "   Although listwise deletion often results in a substantial decrease in the sample size available for the analysis\n",
    "\n",
    "   It is advantageous in particular, under the assumption that data are missing completely at random, it leads to unbiased parameter estimates.but if  when the data are not MCAR, we can get bias results.\n",
    "\n",
    "\n",
    "2) A poor approach--pairwise deletion:\n",
    "\n",
    "             For each pair of variables for which data is available, the correlation coefficient will take that data into account.  Thus, pairwise deletion maximizes all data available by an analysis by analysis basis.  A strength to this technique is that it increases power in your analyses.  \n",
    "             Though this technique is typically preferred over listwise deletion, it also assumes that the missing data are MCAR.\n",
    "     A disadvantage with the use of pairwise deletion is that the standard of errors computed by most software packages uses the average sample size across analyses.  This tends to produced standard of errors that are underestimated or overestimated. \n",
    "     \n",
    "3) Mean substitution:\n",
    "\n",
    "       An old procedure that should certainly be relegated to the past was the idea of substituting a mean for the missing data\n",
    "   For example, if you don't know my systolic blood pressure, just substitute the sample's mean systolic blood pressure for mine and continue. There are a couple of problems with this approach. In the first place it adds no new information. The overall mean, with or without replacing my missing data, will be the same. In addition, such a process leads to an underestimate of error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3d5cb5",
   "metadata": {},
   "source": [
    "## Q8. What are some common post-hoc tests used after ANOVA, and when would you use each one? Provide an example of a situation where a post-hoc test might be necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe68ae4e",
   "metadata": {},
   "source": [
    "If the p-value from the ANOVA is less than the significance level, \n",
    "we can reject the null hypothesis and conclude that we have sufficient evidence to say that at least one of the means of the groups is different from the others.\n",
    "\n",
    "However, this doesn’t tell us which groups are different from each other. \n",
    "It simply tells us that not all of the group means are equal.\n",
    "\n",
    "In order to find out exactly which groups are different from each other, we must conduct a post hoc test.\n",
    "\n",
    "\n",
    "1) Tukey’s Test – useful when you want to make every possible pairwise comparison.\n",
    "\n",
    "To perform Tukey’s test in Python, we can use the pairwise_tukeyhsd() function from the statsmodels library:\n",
    "\n",
    "e.g\n",
    "\n",
    "import statsmodels.stats.multicomp as mc\n",
    "\n",
    "comp = mc.MultiComparison(<dataframe values>)\n",
    "post_hoc_res = comp.tukeyhsd()\n",
    "post_hoc_res.summary()\n",
    "\n",
    "\n",
    "2) Holm’s Method – a slightly more conservative test compared to Tukey’s Test.\n",
    "\n",
    "To perform Tukey’s test in Python, we can use the multi_stats.holm_test() function from the statsmodels library\n",
    "\n",
    "3) Dunnett’s Correction – useful when you want to compare every group mean to a control mean, and you’re not interested in comparing the treatment means with one another.\n",
    "\n",
    "To perform the duns test user neesneedsds to call the  posthoc_dunn() function from the scikit-posthocs library. \n",
    "\n",
    "scikit_posthocs.posthoc_dunn(a, val_col: str = None, group_col: str = None, p_adjust: str = None, sort: bool = True)\n",
    "    \n",
    "    \n",
    "4) BONFERRONI CORRECTION :\n",
    "    Bonferroni was used in a variety of circumstances, most commonly to correct the experiment-wise error rate when using multiple 't' tests or as a post-hoc procedure to correct the family-wise error rate following analysis of variance (anova)\n",
    "    When we conduct multiple hypothesis tests at once, we have to deal with something known as a family-wise error rate, which is the probability that at least one of the tests produces a false positive. This can be calculated as:\n",
    "\n",
    "            Family-wise error rate = 1 – (1-α)n\n",
    "            α: The significance level for a single hypothesis test\n",
    "            n: The total number of tests\n",
    "    A Bonferroni Correction refers to the process of adjusting the alpha (α) level for a family of statistical tests so that we control for the probability of committing a type I error.\n",
    "\n",
    "            The formula for a Bonferroni Correction is as follows:\n",
    "\n",
    "                        αnew = αoriginal / n\n",
    "    \n",
    "import statsmodels.stats.multicomp as mc\n",
    "comp = mc.MultiComparison(<Factores>)\n",
    "tbl, a1, a2 = comp.allpairtest(stats.ttest_ind, method= \"bonf\")\n",
    "tbl\n",
    " \n",
    "5)ANOVA Omnibus Test:\n",
    "    In statistics, an omnibus test is any statistical test that tests for the significance of several parameters in a model at once.\n",
    "    H0: μ1 = μ2 = μ3 = … = μk \n",
    "    HA: At least one population mean is different from the rest\n",
    "\n",
    "       This is an example of an omnibus test because the null hypothesis contains more than two parameters.\n",
    "    With the help of statsmodels.omni_normtest() method, we can get the omnibus test for normality and we use chi^2 score for this statsmodels.omni_normtest() method.\n",
    "    \n",
    "    \n",
    "6) Welch’s ANOVA :\n",
    "        When the assumption of equal variances is violated, Welch’s ANOVA is used as an alternative to the standard one-way ANOVA. A one-way ANOVA (“analysis of variance”) is used to see if there is a statistically significant difference in the means of three or more independent groups.\n",
    "    We can use Bartlett’s test to see if the variances in each group are equal.\n",
    "    stats.bartlett()\n",
    "    The p-value from Bartlett’s test is less than α = .05, which means we can reject the null hypothesis that each group has the same variance\n",
    "        In Python, we can use the Pingouin package’s welch_anova() function to perform Welch’s ANOVA. Make sure we have installed ‘pingouin’ library before applying Welch’s ANOVA\n",
    "    pip install pingouin as pg\n",
    "    pg.welch_anova(dv='', between='', data=df)\n",
    " \n",
    "\n",
    "Example :if you had had three groups in your variable (let's say, students with low stress, moderate stress, high stress) and you wanted to know how big was the effect of stress on student exam performance, you would need to perform a Post-Hoc test if you had a statistically significant independent variable effect on the depedent variable (in this case, the effect of stress on the exam results). You would need a post-hoc test because it might not be clear how exactly stress level tells on student performance (does performance get better with increasing stress? Or do students with a moderate stress perform better than lower and higher stressed students?). In order to answer these questions, we need a post-hoc test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235c0b49",
   "metadata": {},
   "source": [
    "## Q9. A researcher wants to compare the mean weight loss of three diets: A, B, and C. They collect data from 50 participants who were randomly assigned to one of the diets. Conduct a one-way ANOVA using Pythonto determine if there are any significant differences between the mean weight loss of the three diets. Report the F-statistic and p-value, and interpret the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a52b9a4",
   "metadata": {},
   "source": [
    "The F statistic is computed by taking the ratio of what is called the \"between treatment\" variability to the \"residual or error\" variability. \n",
    "H0: means are all equal versus H1: means are not all equal \n",
    "\n",
    "by evaluating variability in the data. The numerator captures between treatment variability (i.e., differences among the sample means) and the denominator contains an estimate of the variability in the outcome. \n",
    "\n",
    "The test statistic is a measure that allows us to assess whether the differences among the sample means (numerator) are more than would be expected by chance if the null hypothesis is true. Recall in the two independent sample test, the test statistic was computed by taking the ratio of the difference in sample means (numerator) to the variability in the outcome (estimated by Sp).  \n",
    "\n",
    "The decision rule for the F test in ANOVA is set up in a similar way to decision rules we established for t tests. The decision rule again depends on the level of significance and the degrees of freedom. The F statistic has two degrees of freedom. These are denoted df1 and df2, and called the numerator and denominator degrees of freedom, respectively. The degrees of freedom are defined as follows:\n",
    "\n",
    "df1 = k-1 and df2=N-k,\n",
    "\n",
    "where k is the number of comparison groups and N is the total number of observations in the analysis.\n",
    "\n",
    "If the null hypothesis is true, the between treatment variation (numerator) will not exceed the residual or error variation (denominator) and the F statistic will small.\n",
    "\n",
    "If the null hypothesis is false, then the F statistic will be large. The rejection region for the F test is always in the upper (right-hand) tail of the distribution as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d4e26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Step 1 - Define the null and alternative hypothesis. \n",
    "\n",
    "H0 -> μ1 = μ2 = μ3 (where μ = mean)\n",
    "Ha -> At least one difference among the means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4eb7baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Step 2 - Find the degree of freedom between and within the groups. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0f7017",
   "metadata": {},
   "outputs": [],
   "source": [
    "df(between)=k-1=no of group-1=3-1=2\n",
    "df_between=2\n",
    "df(within)=n-k=50-3=47\n",
    "df_within=47\n",
    "where \n",
    "n = number of samples in all groups combined.\n",
    "k = number of groups. \n",
    "df_total=df_between +  df_within\n",
    "df_total = 49"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "9acd4ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.195056280737215\n",
      "0.23837582456087233\n",
      "Failed to reject null hypothesis\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import f\n",
    "df_between=2\n",
    "df_within=47\n",
    "Fstat = scipy.stats.f.ppf(q=1-.05, dfn=df_between, dfd= df_within)\n",
    "print(Fstat)\n",
    "p_value = f.sf(Fstat,dfn=df_between,dfd=df_between)\n",
    "print(p_value)\n",
    "if p_value>0.05:\n",
    "    print(\"Failed to reject null hypothesis\")\n",
    "else:\n",
    "    print(\"Reject Null hypothesis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6fc939",
   "metadata": {},
   "outputs": [],
   "source": [
    "Interpretation :There are  no any significant differences between the mean weight loss of the three diets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77728c3",
   "metadata": {},
   "source": [
    "## Q10. A company wants to know if there are any significant differences in the average time it takes to complete a task using three different software programs: Program A, Program B, and Program C. They randomly assign 30 employees to one of the programs and record the time it takes each employee to complete the task. Conduct a two-way ANOVA using Python to determine if there are any main effects or interaction effects between the software programs and employee experience level (novice vs.experienced). Report the F-statistics and p-values, and interpret the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d194f84b",
   "metadata": {},
   "source": [
    "#### Step 1 : Hypothesis:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a92f16",
   "metadata": {},
   "source": [
    "        H0 :There are any no main effects or interaction effects between the software programs and employee experience level\n",
    "        \n",
    "        H1 :There are any no main effects or interaction effects between the software programs and employee experience level"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63996155",
   "metadata": {},
   "source": [
    "#### Step 2 :Alpha : 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715ae83d",
   "metadata": {},
   "source": [
    "#### Step 3 : Decision Boundry\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa1d5bc",
   "metadata": {},
   "source": [
    "\n",
    "If F stat < F(table) stat : Accept the null Hypothesis\n",
    "\n",
    "Else : Reject the null Hypothesis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcd3f8a",
   "metadata": {},
   "source": [
    "#### Step 4: Statastic method repeated measures two_way_anova"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "74181334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              sum_sq    df         F    PR(>F)\n",
      "C(Program)                  0.200000   2.0  0.025905  0.974436\n",
      "C(Experience)              13.611111   1.0  3.525905  0.063887\n",
      "C(Program):C(Experience)    2.022222   2.0  0.261924  0.770195\n",
      "Residual                  324.266667  84.0       NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# create a pandas dataframe with the task completion time data\n",
    "time_data = pd.DataFrame({'Program': ['A', 'B', 'C'] * 30,\n",
    "    'Experience': ['Novice'] * 45 + ['Experienced'] * 45,\n",
    "    'Time': [14, 13, 12, 11, 15, 13, 14, 12, 10, 11, 12, 13, 13, 11, 10, 11, 12, 14, 15, 16, 17, 15, 14, 16, 13, 14, 15, 17, 16, 14] * 3})\n",
    "\n",
    "#print(time_data)\n",
    "#fit the two-way ANOVA model\n",
    "two_way_anova = ols('Time ~ C(Program) + C(Experience) + C(Program):C(Experience)', data=time_data).fit()\n",
    "\n",
    "# print the ANOVA table\n",
    "print(sm.stats.anova_lm(two_way_anova, typ=2))\n",
    "#statsmodels.formula.api module. We include the main effects of Program and Experience, as well as the interaction effect between Program and Experience, in the model formula. We print the ANOVA table using the anova_lm function from the statsmodels.stats.anova module.\n",
    "\n",
    "#If the ANOVA results show significant main effects or interaction effects, we can interpret them as follows:\n",
    "\n",
    "#Main effect of Program: If the p-value associated with the Program factor is less than the chosen significance level (e.g., 0.05), we can conclude that there is a significant main effect of the software program on task completion time. This means that there are significant differences in task completion time between the three programs, regardless of the employee experience level.\n",
    "\n",
    "#Main effect of Experience: If the p-value associated with the Experience factor is less than the chosen significance level, we can conclude that there is a significant main effect of the employee experience level on task completion time. This means that there are significant differences in task completion time between novice and experienced employees, regardless of the software program used.\n",
    "\n",
    "#Interaction effect between Program and Experience: If the p-value associated with the interaction term (Program:Experience) is less than the chosen significance level, we can conclude that there is a significant interaction effect between the software program and employee experience level on task completion time. This means that the effect of the software program on task completion time depends on the employee experience level. In other words, the difference in task completion time between software programs may be different for novice employees than for experienced employees.\n",
    "\n",
    "#It's also worth noting that the two-way ANOVA assumes that the residuals (differences between the actual values and predicted values) are normally distributed and have equal variances across the groups. If these assumptions are violated, the results may not be accurate. Therefore, it's important to check the residuals for normality and equality of variances before interpreting the ANOVA results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0775368",
   "metadata": {},
   "outputs": [],
   "source": [
    "F stat : of C (Program)= 0.025905\n",
    "F stat : of C(Experience) = 3.525905  \n",
    "F stat : C(Program):C(Experience) = 0.261924  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82da5541",
   "metadata": {},
   "outputs": [],
   "source": [
    "P Value : C(Program)  :0.974436\n",
    "P Value : C(Experience)  :0.974436\n",
    "P Value : C(Program):C(Experience)   :0.974436\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03eeb580",
   "metadata": {},
   "source": [
    "**Inference** :P Value : C(Program):C(Experience)   :0.974436>0.05\n",
    "\n",
    "        Failed to reject Null Hypothesis\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae28c0b3",
   "metadata": {},
   "source": [
    " **Interpretation** :There are any no main effects or interaction effects between the software programs and employee experience level"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df979bcc",
   "metadata": {},
   "source": [
    "## Q 11. An educational researcher is interested in whether a new teaching method improves student test scores. They randomly assign 100 students to either the control group (traditional teaching method) or the experimental group (new teaching method) and administer a test at the end of the semester. Conduct a two-sample t-test using Python to determine if there are any significant differences in test scoresbetween the two groups. If the results are significant, follow up with a post-hoc test to determine which group(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44522929",
   "metadata": {},
   "source": [
    "**Hypothesis**:\n",
    "            H0 : There is no significance difference between test score between two groups\n",
    "            \n",
    "            H1 : There is  significance difference between test score between two groups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f9f0a7",
   "metadata": {},
   "source": [
    "**Alpha : 0.05**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf63fd27",
   "metadata": {},
   "source": [
    "**Check The normality:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "072785fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[59 85 42 59 66 58 88 69 71 59 44 52 72 62 64 63 70 75 80 46 74 45 40 41\n",
      " 47 55 88 42 56 76 74 67 50 74 78 59 84 46 42 75 60 66 43 89 40 70 51 84\n",
      " 66 46 55 67 62 81 52 42 44 82 57 82 84 53 79 78 49 56 40 76 56 64 55 73\n",
      " 71 43 70 86 46 67 42 82 72 53 81 43 44 79 79 41 68 50 54 53 76 73 64 40\n",
      " 49 41 84 87]\n",
      "[62 69 65 72 52 86 67 51 90 49 67 78 75 70 56 67 56 45 44 55 77 45 79 74\n",
      " 53 70 57 52 57 65 58 63 47 43 48 75 92 63 74 85 83 58 64 69 40 53 63 45\n",
      " 81 70 61 89 46 67 84 48 41 85 71 68 65 80 85 73 77 47 85 65 92 82 74 70\n",
      " 67 48 86 73 70 53 87 40 64 50 90 72 41 77 49 55 49 65 68 45 73 66 42 65\n",
      " 55 56 48 66]\n",
      "    X1  X2\n",
      "0   59  62\n",
      "1   85  69\n",
      "2   42  65\n",
      "3   59  72\n",
      "4   66  52\n",
      "..  ..  ..\n",
      "95  40  65\n",
      "96  49  55\n",
      "97  41  56\n",
      "98  84  48\n",
      "99  87  66\n",
      "\n",
      "[100 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "x1=np.random.randint(40,90,100)\n",
    "print(x1)\n",
    "x2=np.random.randint(40,93,100)\n",
    "print(x2)\n",
    "\n",
    "df = pd.DataFrame({'X1' :x1,'X2' : x2})\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0ead335b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShapiroResult(statistic=0.9511916637420654, pvalue=0.0009947631042450666)\n"
     ]
    }
   ],
   "source": [
    "print (stats.shapiro(x1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "11f6dda9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShapiroResult(statistic=0.9538914561271667, pvalue=0.0015106657519936562)\n"
     ]
    }
   ],
   "source": [
    "print (stats.shapiro(x2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca811c16",
   "metadata": {},
   "source": [
    "**Check the varience:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1868cc",
   "metadata": {},
   "source": [
    "H0 : Varience are equal\n",
    "\n",
    "H1 : Varience are not equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bb7b6b03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeveneResult(statistic=0.05323621128263862, pvalue=0.817763000867354)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.levene(x1,x2,center='mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21110bec",
   "metadata": {},
   "source": [
    "Here p > alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d106bdaa",
   "metadata": {},
   "source": [
    "**Test : t sample test for equal varience**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "658524e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=-0.44168155086783245, pvalue=0.6592016497841472)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "stats.ttest_ind(x1,x2,equal_var=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516b2ec4",
   "metadata": {},
   "source": [
    "### Inference:\n",
    "**Based on p value we accept the null hypothesis : pvalue=0.66**\n",
    "\n",
    "**There is no significance difference between test score between two groups**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e8c70c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi2 result of the contingency table: 304.5590034010797, p-value: 8.926781490543114e-23\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "chi2, p, dof, ex = chi2_contingency(df, correction=True)\n",
    "print(f\"Chi2 result of the contingency table: {chi2}, p-value: {p}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e96bd342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple Comparison of Means - Tukey HSD, FWER=0.05\n",
      "===================================================\n",
      "group1 group2 meandiff p-adj   lower  upper  reject\n",
      "---------------------------------------------------\n",
      "    x1     x2     2.17 0.2934 -1.8923 6.2323  False\n",
      "---------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#create DataFrame to hold data\n",
    "df = pd.DataFrame({'score': [59,85,42,59,66,58,88,69,71,59,44,52,72,62,64,63,70,75,80,46,74,45,40,41,\n",
    " 47, 55, 88, 42, 56, 76, 74, 67, 50, 74, 78, 59, 84, 46, 42, 75, 60, 66, 43, 89, 40, 70, 51, 84,\n",
    " 66, 46, 55, 67, 62, 81, 52, 42, 44, 82, 57, 82, 84, 53, 79, 78, 49, 56, 40, 76, 56, 64, 55, 73,\n",
    " 71, 43, 70 ,86, 46 ,67 ,42 ,82 ,72, 53, 81 ,43, 44 ,79 ,79, 41, 68, 50, 54, 53, 76, 73, 64 ,40,\n",
    " 49 ,41, 84 ,87,62 ,69, 65, 72, 52, 86, 67, 51 ,90, 49 ,67 ,78 ,75,70 ,56 ,67, 56 ,45, 44, 55, 77, 45, 79, 74,\n",
    " 53, 70 ,57, 52 ,57 ,65 ,58 ,63 ,47, 43 ,48 ,75, 92 ,63, 74 ,85 ,83, 58 ,64 ,69 ,40, 53, 63, 45,\n",
    " 81, 70, 61, 89 ,46, 67 ,84, 48, 41 ,85, 71 ,68, 65, 80, 85,73, 77, 47 ,85, 65, 92, 82, 74, 70,\n",
    " 67 ,48, 86 ,73, 70 ,53 ,87, 40, 64, 50 ,90 ,72, 41, 77, 49 ,55 ,49, 65, 68, 45 ,73, 66, 42, 65,\n",
    " 55, 56 ,48 ,66],\n",
    "                   'group': np.repeat(['x1','x2'], repeats=100)}) \n",
    "\n",
    "# perform Tukey's test\n",
    "tukey = pairwise_tukeyhsd(endog=df['score'],\n",
    "                          groups=df['group'],\n",
    "                          alpha=0.05)\n",
    "\n",
    "#display results\n",
    "print(tukey)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fc2658",
   "metadata": {},
   "outputs": [],
   "source": [
    "P-value for the difference in means between x1 and x2: .2934 >0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3166bd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "Thus, we would conclude not a statistically significant difference between the means of groups x1 and x2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cedec5",
   "metadata": {},
   "source": [
    "## Q12. A researcher wants to know if there are any significant differences in the average daily sales of three retail stores: Store A, Store B, and Store C. They randomly select 30 days and record the sales for each store on those days. Conduct a repeated measures ANOVA using Python to determine if there are any significant differences in sales between the three stores. If the results are significant, follow up with a post-hoc test to determine which store(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3976a11f",
   "metadata": {},
   "source": [
    "**Step 1: Make the hypothesis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053dc308",
   "metadata": {},
   "outputs": [],
   "source": [
    "H0 :There is no significant differences in sales between the three stores\n",
    "H1 : There is  significant differences in sales between the three stores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332950a1",
   "metadata": {},
   "source": [
    "**Step 2:Significance level**\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d07afa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Alpha = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d94c52a",
   "metadata": {},
   "source": [
    "**Step 3 : Decision Boundry**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c80bbe",
   "metadata": {},
   "source": [
    "If F stat < F(table) stat : Accept the null Hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd657ac",
   "metadata": {},
   "source": [
    "Else : Reject the null Hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2cba2ca",
   "metadata": {},
   "source": [
    "**Step 4: Statastic method repeated measures ANOVA model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd23c65f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                sum_sq    df             F  PR(>F)\n",
      "C(Store)  1.087149e-28   2.0  1.484803e-29     1.0\n",
      "Residual  3.185000e+02  87.0           NaN     NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Create a DataFrame with the sales data\n",
    "data = pd.DataFrame({\n",
    "    'Store': ['A'] * 30 + ['B'] * 30 + ['C'] * 30,\n",
    "    'Sales': [10, 8, 12, 9, 11, 13, 14, 15, 13, 12,\n",
    "              11, 10, 8, 9, 12, 13, 11, 10, 9, 12,\n",
    "              14, 13, 11, 12, 10, 9, 8, 11, 12, 13,\n",
    "              12, 10, 8, 9, 11, 13, 14, 15, 13, 12,\n",
    "              11, 10, 8, 9, 12, 13, 11, 10, 9, 12,\n",
    "              14, 13, 11, 12, 10, 9, 8, 11, 12, 13,\n",
    "              12, 10, 8, 9, 11, 13, 14, 15, 13, 12,\n",
    "              11, 10, 8, 9, 12, 13, 11, 10, 9, 12,\n",
    "              14, 13, 11, 12, 10, 9, 8, 11, 12, 13]\n",
    "})\n",
    "\n",
    "# Fit a repeated measures ANOVA model\n",
    "model = ols('Sales ~ C(Store)', data=data).fit()\n",
    "\n",
    "# Print the ANOVA table\n",
    "table = sm.stats.anova_lm(model, typ=2)\n",
    "print(table)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4104819",
   "metadata": {},
   "source": [
    "**Inference : p>0.05 : Do not reject the Null Hypothesis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d18e6d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple Comparison of Means - Tukey HSD, FWER=0.05\n",
      "================================================\n",
      "group1 group2 meandiff p-adj lower  upper reject\n",
      "------------------------------------------------\n",
      "     A      B      0.0   1.0 -1.178 1.178  False\n",
      "     A      C      0.0   1.0 -1.178 1.178  False\n",
      "     B      C      0.0   1.0 -1.178 1.178  False\n",
      "------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Perform a post-hoc test (Tukey's HSD)\n",
    "posthoc = pairwise_tukeyhsd(data['Sales'], data['Store'], alpha=0.05)\n",
    "print(posthoc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2c7ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "P-value for the difference in means between x1 and x2: 1 >0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2401ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "Thus, we would conclude there is no significant differences in sales between the three stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f2afc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddd4201",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cebd03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118f5ea3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9c7852",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92ca2af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35018dcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767cc5a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57280365",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe69c128",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bee7aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23075eb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e295eefc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30441c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fe80a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c8f578",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b29859",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bdc59c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3add790",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d057090",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8835cf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9065af40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed824681",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5840d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5112497e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f86e5bc",
   "metadata": {},
   "source": [
    "## Q6. Suppose you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02. What can you conclude about the differences between the groups, and how would you interpret these results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56a8fa5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6a19d014",
   "metadata": {},
   "source": [
    "## Q7. In a repeated measures ANOVA, how would you handle missing data, and what are the potential consequences of using different methods to handle missing data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ee6751",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ad2f0fc6",
   "metadata": {},
   "source": [
    "## Q8. What are some common post-hoc tests used after ANOVA, and when would you use each one? Provide an example of a situation where a post-hoc test might be necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265b2676",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3d913635",
   "metadata": {},
   "source": [
    "## Q9. A researcher wants to compare the mean weight loss of three diets: A, B, and C. They collect data from 50 participants who were randomly assigned to one of the diets. Conduct a one-way ANOVA using Python to determine if there are any significant differences between the mean weight loss of the three diets. Report the F-statistic and p-value, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccab8bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b48101a1",
   "metadata": {},
   "source": [
    "## Q10. A company wants to know if there are any significant differences in the average time it takes to complete a task using three different software programs: Program A, Program B, and Program C. They randomly assign 30 employees to one of the programs and record the time it takes each employee to complete the task. Conduct a two-way ANOVA using Python to determine if there are any main effects or interaction effects between the software programs and employee experience level (novice vs.experienced). Report the F-statistics and p-values, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0565d684",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "390db0a3",
   "metadata": {},
   "source": [
    "## Q11. An educational researcher is interested in whether a new teaching method improves student test scores. They randomly assign 100 students to either the control group (traditional teaching method) or the experimental group (new teaching method) and administer a test at the end of the semester. Conduct a two-sample t-test using Python to determine if there are any significant differences in test scores between the two groups. If the results are significant, follow up with a post-hoc test to determine which group(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80db611",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "581a356f",
   "metadata": {},
   "source": [
    "##  Q12. A researcher wants to know if there are any significant differences in the average daily sales of three retail stores: Store A, Store B, and Store C. They randomly select 30 days and record the sales for each store on those days. Conduct a repeated measures ANOVA using Python to determine if there are any significant differences in sales between the three stores. If the results are significant, follow up with a post-hoc test to determine which store(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54cf3d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861f3d7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34b46e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
